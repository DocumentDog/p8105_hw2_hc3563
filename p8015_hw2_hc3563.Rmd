---
title: "p8105_hw2_hc3563"
author: "Hanchuan Chen"
date: "2024-10-01"
output: github_document
---
Let's start with implementing library:
```{r}
library(tidyverse)
```


### Problem 1
```{r data_setup}
subway_df =
  read_csv(file='./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv', na=c("NA",".","")) |>  
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) |> 
  mutate(entry = if_else(entry == "Yes", TRUE, FALSE)) |> 
  drop_na(line, station_name, station_longitude, station_latitude, entry, vending, entrance_type, ada)
```
So far I have read and cleaned the dataset. First I imported the dataset and clean the column names. Then I subset the columns I want to keep; finally I change the value in "entry" column from "Yes/No" to "TRUE/FALSE" and dropped all columns except routes since not all stations have 11 lines. Now the dataset the clean enough and has `r nrow(subway_df)` rows and `r ncol(subway_df)` columns. 
```{r questions}
#distinct station
distinct_station = subway_df |> distinct(line, station_name)
n_distinct = nrow(distinct_station)

#ADA compliant
ada_compliant = subway_df |> filter(ada == TRUE)
n_ada = nrow(ada_compliant)

#vending
vending_yes = subway_df |> filter(vending == "YES")
prop_vending = nrow(vending_yes) / nrow(subway_df)

#distinct station that serve A train
A_train = 
  subway_df |> 
  distinct(line, station_name, route1) |> 
  filter(route1 == 'A')
n_a_train = nrow(A_train)

#ADA compliant among A train serving
ada_and_A = 
  subway_df |> 
  distinct(line, station_name, route1, ada) |> 
  filter(route1 == 'A' & ada == TRUE)
n_ada_and_A = nrow(ada_and_A)
```
Using the data, we can see there are `r n_distinct` distinct stations, `r n_ada` stations are ADA compliant, and about `r prop_vending` of station entrance have vending machines. Among these distinct stations, there are `r n_a_train` stations serve A train. Among stations which serve A train, there are `r n_ada_and_A` stations are ADA compliant.

### Problem 2
```{r clean}
trashwheel_df = 
  readxl::read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet=1) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster) |> 
  mutate(sports_balls = as.integer(sports_balls)) |> 
  mutate(name = "trash_wheel") |> 
  mutate(year = as.numeric(year))

professor_df = 
  readxl::read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet=2) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster, date) |> 
  mutate(name = "professor")

gwynnda_df =
  readxl::read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet=4) |> 
  janitor::clean_names() |> 
  select(dumpster:homes_powered) |> 
  drop_na(dumpster) |> 
  mutate(name = "gwynnda")

#bind the three datasets
full_df = bind_rows(trashwheel_df, professor_df, gwynnda_df)
```
By importing and cleaning excel tables, there are now three datasets available: trashwheel_df, professor_df, and gwynnda_df. For trashwheel_df, which is the first sheet in excel, there are `r nrow(trashwheel_df)` rows and `r ncol(trashwheel_df)` columns, and the variables are shown below: `r names(trashwheel_df)`. Professor_df has `r nrow(professor_df)` rows and `r ncol(professor_df)` columns; gwynnda_df has `r nrow(gwynnda_df)` rows and `r ncol(gwynnda_df)` columns, while both datasets do not contain "sports_balls" variable.
```{r}
total_weight = sum(professor_df$weight_tons)

total_butts =
  gwynnda_df |> 
  filter(month == "June" & year == 2022) |> 
  pull(cigarette_butts) |> 
  sum()
```
From professor_df, we can see that the total weight of trash collected by professor trash wheel is `r total_weight` tons. Also, the total number of cigarette butts collected by Gwynnda in June of 2022 is `r total_butts`.


### Problem 3
```{r}
bakers_df = 
  read_csv("./data/gbb_datasets/bakers.csv") |> 
  janitor::clean_names() |> 
  rename(baker = baker_name) |> 
  mutate(baker = word(baker, 1))

bakes_df = 
  read_csv("./data/gbb_datasets/bakes.csv") |> 
  janitor::clean_names()

results_df = 
  read_csv("./data/gbb_datasets/results.csv", skip=2) |> 
  janitor::clean_names() 
```

```{r left_join}
results_bakers_df = left_join(results_df, bakers_df, by=c("baker","series"))
full_df = left_join(results_bakers_df, bakes_df, by=c("baker","series","episode"))
full_df = 
  full_df |> 
  drop_na(result) |> 
  arrange(series, baker, episode)
```

```{r output}
write.csv(full_df, file="./data/merged_data.csv", row.names = FALSE)
```

The code above is the whole process of dealing with these three datasets. First I imported each of them take a look of each dataset. I found that in "bakers" dataset the column name of the bakers are different from other two datasets, and this dataset contains the full name but other two only have first name. So I rename the column and subset the first name in this dataset to make sure it can merge with other two. In the "results" dataset the first two rows are comments so I skipped them. 

In the joining process, I first left join bakers to results dataset since results table has the full records so set it as left table will not lose records; also I joined these two tables by using two variables: baker and series, as there are one baker showed in different series. Then I used this joined table as left table and left joined "bakes" table. I added "episode" as unique variable to make sure it won't cause many to many join. Next, I dropped the missing values contained in result column and sort the table by series, baker, and episode, so it is clear so see in which series, which episode does the baker get in to the next round or get out. 

```{r}
winner_df = 
  full_df |> 
  filter(series >= 5 & series <= 10) |> 
  filter(result == "STAR BAKER" | result == "WINNER") |> 
  arrange(series, episode)

knitr::kable(winner_df, format = "html")
```
From this table we can see that usually the winner came from the star baker in each episode and the technical score is usually 1 or 2, which is pretty predictable.


```{r}
viewers_df = 
  read_csv("./data/gbb_datasets/viewers.csv")

head(viewers_df, 10)

mean_1 = mean(viewers_df$`Series 1`, na.rm = TRUE)
mean_5 = mean(viewers_df$`Series 5`, na.rm = TRUE)
```

From the table "viewers" we can see that the mean viewship for season 1 is `r mean_1` and for season 5 is `r mean_5`.




















